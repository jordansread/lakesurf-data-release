
target_default: 1_spatial

packages:
  - yaml
  - dplyr
  - meddle
  - readr
  - rgdal
  - httr
  - lwgeom
  - stringr
  - sf


sources:
  - src/spatial_utils.R
  - src/file_utils.R
  - src/group_utils.R

targets:
  1_spatial:
    depends:
      - out_data/lake_metadata.csv
      - out_data/lake_surface_temp_obs.csv


  us_counties_sf:
    command: fetch_zip_url_sf(I('https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_5m.zip'),
      layer_name = I('cb_2018_us_county_5m'))

  spatial_metadata:
    command: extract_feature(modeled_centroids_sf)

  modeled_centroids_sf:
    command: sf_centroid_metadata('out_data/lake_metadata.csv')

# make a grid that doesn't depend on the centroids
  release_grid_sf:
    command: generate_group_rects()


  weather_centroids:
    command: ldas_centroid_lat_lon(x0 = I(-124.9375), y0 = I(25.0625), x_num = I(464), y_num = I(224), cell_res = I(0.125))

# need to add:
# - n_obs instead of observed: TRUE/FALSE
# - rmse_ealstm, rmse_xgboost, rmse_lm from "error_per_site.csv"
# - 3fold_fold` `5fold_fold cluster ID
# TO DO!!! get num_obs from the other pred file, not from this metadata file!!
  metadata_tbl:
    command: build_metadata(target_name, 'in_data/surface_lake_metadata_file.csv',
      error_fl = 'in_data/err_per_site_062321.csv',
      cluster_fl = 'in_data/Lake Clustering Metadata - Sheet1.csv',
      release_grid_sf = release_grid_sf, weather_centroids = weather_centroids)

  out_data/lake_metadata.csv:
    command: subset_write(target_name, metadata_tbl, remove_cols = I(c('x','y')))


